{
    "activation": "relu",
    "agent_buffer_size": 100000,
    "agent_buffer_start_size": 10000,
    "agent_d_hidden_layers": [
        32
    ],
    "agent_learning_rate": 0.0001,
    "baseline": "shared_advantage",
    "baseline_d_hidden_layers": [],
    "baseline_learning_rate": 0.0001,
    "batch_size": 8,
    "clip_range": 0.1,
    "env_name": "PongNoFrameskip-v4",
    "experiment_folder": "/home/raoul/results/1",
    "gae_lamda": 0.97,
    "global_step": 0,
    "log_step": 1000,
    "model_name": "ppo",
    "n_steps": 4000000,
    "reward_discount_factor": 0.99,
    "save_freq": 1000000,
    "seed": 0,
    "update_target_network_freq": 1000,
    "verbose": false
}